{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7506b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img , img_to_array , ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input , decode_predictions , VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e25584",
   "metadata": {},
   "source": [
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ccef4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_img(r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\traning\\dogs\\dog.4105.jpg\" , target_size=(224 , 224))\n",
    "image = img_to_array(image)\n",
    "image = image.reshape((1 , image.shape[0] , image.shape[1] , image.shape[2]))\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb835b",
   "metadata": {},
   "source": [
    "### VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1134f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d229bf2",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13f12310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 420ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(image)\n",
    "label = decode_predictions(yhat)\n",
    "label = label[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b7e085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great_Dane(34.77%) \n"
     ]
    }
   ],
   "source": [
    "print(\"%s(%.2f%%) \" % (label[1] , label[2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d985b1d",
   "metadata": {},
   "source": [
    "# ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301eb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input , decode_predictions \n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d411b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "55533fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\traning\\cats\\cat.4103.jpg\" , target_size=(224 , 224))\n",
    "image = img_to_array(img)\n",
    "image = np.expand_dims(image , axis=0)\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d2bef80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c2e11b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n02124075', 'Egyptian_cat', 0.47569656), ('n02123159', 'tiger_cat', 0.2789537), ('n02123045', 'tabby', 0.16371466)]\n"
     ]
    }
   ],
   "source": [
    "print(decode_predictions(preds , top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "448e15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = decode_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2903d3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n02124075', 'Egyptian_cat', 0.47569656),\n",
       "  ('n02123159', 'tiger_cat', 0.2789537),\n",
       "  ('n02123045', 'tabby', 0.16371466),\n",
       "  ('n02127052', 'lynx', 0.047741927),\n",
       "  ('n04493381', 'tub', 0.0032482422)]]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f148432f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('n02124075', 'Egyptian_cat', 0.47569656)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "905654dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egyptian_cat(47.57%) \n"
     ]
    }
   ],
   "source": [
    "print(\"%s(%.2f%%) \" % (label[0][0][1] , label[0][0][2]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fefda0",
   "metadata": {},
   "source": [
    "# vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6c7257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\traning\"\n",
    "test_path = r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\test\"\n",
    "valid_path = r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3416b18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2702 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 266 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "directory=train_path , target_size=(224 , 224 ) , batch_size=10)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "directory=valid_path , target_size=(224 , 224 ) , batch_size=10)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "directory=test_path , target_size=(224 , 224 ) , batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9acdcac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac7ae03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = keras.Sequential()\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    model1.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae4dc4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model1.layers:\n",
    "    layer.trainabler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e3c12a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.add(keras.layers.Dense(3 , activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfaa1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=\"adam\" , loss=\"categorical_crossentropy\" , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe7eca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4 batches). You may need to use the repeat() function when building your dataset.\n",
      "4/4 - 32s - loss: 1220.4780 - accuracy: 0.3500 - val_loss: 36.9166 - val_accuracy: 0.3333 - 32s/epoch - 8s/step\n",
      "Epoch 2/5\n",
      "4/4 - 29s - loss: 12.2264 - accuracy: 0.4500 - 29s/epoch - 7s/step\n",
      "Epoch 3/5\n",
      "4/4 - 27s - loss: 1.7609 - accuracy: 0.4500 - 27s/epoch - 7s/step\n",
      "Epoch 4/5\n",
      "4/4 - 29s - loss: 2.6540 - accuracy: 0.3750 - 29s/epoch - 7s/step\n",
      "Epoch 5/5\n",
      "4/4 - 28s - loss: 1.3621 - accuracy: 0.3000 - 28s/epoch - 7s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233e1e71f40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_batches , validation_data=valid_batches , steps_per_epoch=4 , validation_steps=4 , epochs=5 , verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0637e4",
   "metadata": {},
   "source": [
    "# mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54b20f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38b8eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\traning\"\n",
    "test_path = r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\test\"\n",
    "valid_path = r\"C:\\Users\\USER_PC_SA\\Desktop\\Ai project\\scraping_project\\My_Data\\prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1abc4f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2702 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 3 classes.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 266 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "directory=train_path , target_size=(224 , 224 ) , batch_size=10)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "directory=valid_path , target_size=(224 , 224 ) , batch_size=10)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "directory=test_path , target_size=(224 , 224 ) , batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66828e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "928f0a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = keras.Sequential()\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    model1.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a873f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model1.layers:\n",
    "    layer.trainabler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a563d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import keras\\nimport tensorflow as tf'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.add(keras.layers.Dense(3 , activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bd063a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=\"adam\" , loss=\"categorical_crossentropy\" , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c48db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(train_batches , validation_data=valid_batches , steps_per_epoch=4 , validation_steps=4 , epochs=5 , verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7139912",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use mobilenet accuracy == 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fe2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
